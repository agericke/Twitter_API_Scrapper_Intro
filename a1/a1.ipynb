{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS579: Assignment 1\n",
    "<br>\n",
    "-  In this assignment, we'll implement community detection and link prediction algorithms using Facebook \"like\" data.\n",
    "<br><br>\n",
    "-  The file `edges.txt.gz` indicates like relationships between facebook users. This was collected using snowball sampling: beginning with the user \"Bill Gates\", I crawled all the people he \"likes\", then, for each newly discovered user, I crawled all the people they liked.\n",
    "<br><br>\n",
    "-  We'll cluster the resulting graph into communities, as well as recommend friends for Bill Gates.\n",
    "<br><br>\n",
    "-  Complete the **15** methods below that are indicated by `TODO`. I've provided some sample output to help guide your implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should not use any imports not listed here:\n",
    "from collections import Counter, defaultdict, deque\n",
    "import copy\n",
    "from itertools import combinations\n",
    "import math\n",
    "import networkx as nx\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Community Detection\n",
    "\n",
    "def example_graph():\n",
    "    \"\"\"\n",
    "    Create the example graph from class. Used for testing.\n",
    "    Do not modify.\n",
    "    \"\"\"\n",
    "    g = nx.Graph()\n",
    "    g.add_edges_from([('A', 'B'), ('A', 'C'), ('B', 'C'), ('B', 'D'), ('D', 'E'), ('D', 'F'), ('D', 'G'), ('E', 'F'), ('G', 'F')])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agericke/anaconda3/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:611: MatplotlibDeprecationWarning: isinstance(..., numbers.Number)\n",
      "  if cb.is_numlike(alpha):\n"
     ]
    }
   ],
   "source": [
    "graph = example_graph()\n",
    "nx.draw(graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "for node in graph.nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B']\n",
      "('A', 'B')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'count',\n",
       " 'index']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(list)\n",
    "a = sorted(('B', 'A'))\n",
    "print(a)\n",
    "a = tuple(a)\n",
    "print(a)\n",
    "dir(tuple)\n",
    "#print(a.__hash__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function __contains__:\n",
      "\n",
      "__contains__(key, /) method of collections.defaultdict instance\n",
      "    True if the dictionary has the specified key, else False.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'append',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'sort']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(defaultdict)\n",
    "node2distances = defaultdict(int)\n",
    "node2distances['C'] = 1\n",
    "help(node2distances.__contains__)\n",
    "list(node2distances.items())\n",
    "dir(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'E': 0, 'D': 1, 'F': 1, 'B': 2, 'G': 2, 'A': 3, 'C': 3})\n",
      "[('A', 3), ('B', 2), ('C', 3), ('D', 1), ('E', 0), ('F', 1), ('G', 2)]\n",
      "[('A', 1), ('B', 1), ('C', 1), ('D', 1), ('E', 1), ('F', 1), ('G', 2)]\n",
      "[('A', ['B']), ('B', ['D']), ('C', ['B']), ('D', ['E']), ('F', ['E']), ('G', ['D', 'F'])]\n"
     ]
    }
   ],
   "source": [
    "def bfs(graph, root, max_depth):\n",
    "    \"\"\"\n",
    "    Perform breadth-first search to compute the shortest paths from a root node to all\n",
    "    other nodes in the graph. To reduce running time, the max_depth parameter ends\n",
    "    the search after the specified depth.\n",
    "    E.g., if max_depth=2, only paths of length 2 or less will be considered.\n",
    "    This means that nodes greather than max_depth distance from the root will not\n",
    "    appear in the result.\n",
    "\n",
    "    You may use these two classes to help with this implementation:\n",
    "      https://docs.python.org/3.5/library/collections.html#collections.defaultdict\n",
    "      https://docs.python.org/3.5/library/collections.html#collections.deque\n",
    "\n",
    "    Params:\n",
    "      graph.......A networkx Graph\n",
    "      root........The root node in the search graph (a string). We are computing\n",
    "                  shortest paths from this node to all others.\n",
    "      max_depth...An integer representing the maximum depth to search.\n",
    "\n",
    "    Returns:\n",
    "      node2distances...dict from each node to the length of the shortest path from\n",
    "                       the root node\n",
    "      node2num_paths...dict from each node to the number of shortest paths from the\n",
    "                       root node to this node.\n",
    "      node2parents.....dict from each node to the list of its parents in the search\n",
    "                       tree\n",
    "\n",
    "    In the doctests below, we first try with max_depth=5, then max_depth=2.\n",
    "\n",
    "    >>> node2distances, node2num_paths, node2parents = bfs(example_graph(), 'E', 5)\n",
    "    >>> sorted(node2distances.items())\n",
    "    [('A', 3), ('B', 2), ('C', 3), ('D', 1), ('E', 0), ('F', 1), ('G', 2)]\n",
    "    >>> sorted(node2num_paths.items())\n",
    "    [('A', 1), ('B', 1), ('C', 1), ('D', 1), ('E', 1), ('F', 1), ('G', 2)]\n",
    "    >>> sorted((node, sorted(parents)) for node, parents in node2parents.items())\n",
    "    [('A', ['B']), ('B', ['D']), ('C', ['B']), ('D', ['E']), ('F', ['E']), ('G', ['D', 'F'])]\n",
    "    >>> node2distances, node2num_paths, node2parents = bfs(example_graph(), 'E', 2)\n",
    "    >>> sorted(node2distances.items())\n",
    "    [('B', 2), ('D', 1), ('E', 0), ('F', 1), ('G', 2)]\n",
    "    >>> sorted(node2num_paths.items())\n",
    "    [('B', 1), ('D', 1), ('E', 1), ('F', 1), ('G', 2)]\n",
    "    >>> sorted((node, sorted(parents)) for node, parents in node2parents.items())\n",
    "    [('B', ['D']), ('D', ['E']), ('F', ['E']), ('G', ['D', 'F'])]\n",
    "    \"\"\"\n",
    "    q = deque()\n",
    "    q.append(root)\n",
    "    seen = set()       # nodes we have already visited.\n",
    "    res = []\n",
    "    depth = 1  # Track depth of the search\n",
    "    node2distances = defaultdict(int)\n",
    "    node2num_paths = defaultdict(int)\n",
    "    node2parents = defaultdict(list)\n",
    "    node2distances[root] = 0\n",
    "    node2num_paths[root] = 1\n",
    "    if max_depth == 0:\n",
    "        return node2distances, node2num_paths, node2parents\n",
    "    while len(q) > 0:  # while more to visit\n",
    "        n = q.popleft()\n",
    "        if n == 'null':\n",
    "            depth += 1\n",
    "            continue\n",
    "        if depth > max_depth:\n",
    "            return node2distances, node2num_paths, node2parents\n",
    "        if n not in seen:\n",
    "            res.append(n)\n",
    "            seen.add(n)\n",
    "        for nn in graph.neighbors(n):\n",
    "            if nn not in seen:\n",
    "                if not q.__contains__(nn):\n",
    "                    q.append(nn)\n",
    "                if not node2distances.__contains__(nn):\n",
    "                    node2distances[nn] = depth\n",
    "            if node2distances[nn] == (node2distances[n]+1):\n",
    "                node2parents[nn].append(n)\n",
    "                node2num_paths[nn] += 1 \n",
    "        q.append('null')\n",
    "        if n == root:\n",
    "            depth += 1\n",
    "    return node2distances, node2num_paths, node2parents\n",
    "\n",
    "node2distances, node2num_paths, node2parents = bfs(graph, 'E', 5)\n",
    "print(node2distances)\n",
    "print(sorted(node2distances.items()))\n",
    "print(sorted(node2num_paths.items()))\n",
    "print(sorted((node, sorted(parents)) for node, parents in node2parents.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cabron\n",
      "[('D', ['E']), ('F', ['E']), ('B', ['D']), ('G', ['D', 'F']), ('A', ['B']), ('C', ['B'])]\n",
      "cabron2\n"
     ]
    }
   ],
   "source": [
    "node2distances_order = sorted(node2distances.items(), key=lambda x:(-x[1], x[0]))\n",
    "#for k,v in node2distances_order:\n",
    "    #print(k)\n",
    "    #print(v)\n",
    "    #print('\\n')\n",
    "    \n",
    "result = defaultdict(float)\n",
    "resulta = dict()\n",
    "resulta['k'] = 'b'\n",
    "list(resulta.items())\n",
    "a = list([('A', 'B'), ('C', 'D')])\n",
    "dir(list)\n",
    "a.append(('G','Z'))\n",
    "b = dict()\n",
    "b[('A', 'B')] = 3\n",
    "list(b.items())\n",
    "#list(('a','b')).items()\n",
    "node2distances_order = sorted(node2distances.items(), key=lambda x:(-x[1], x[0]))\n",
    "keys_ = list(dict(node2distances_order).keys())\n",
    "\n",
    "#q = deque()\n",
    "if ('Z') not in node2distances.keys():\n",
    "    print('cabron')\n",
    "    \n",
    "print(list(node2parents.items()))\n",
    "if ('F') not in node2parents.values():\n",
    "    print('cabron2')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('A', 'B'), 1.0),\n",
       " (('B', 'C'), 1.0),\n",
       " (('B', 'D'), 3.0),\n",
       " (('D', 'E'), 4.5),\n",
       " (('D', 'G'), 0.5),\n",
       " (('E', 'F'), 1.5),\n",
       " (('F', 'G'), 0.5)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bottom_up(root, node2distances, node2num_paths, node2parents):\n",
    "    \"\"\"\n",
    "    Compute the final step of the Girvan-Newman algorithm.\n",
    "    See p 352 From your text:\n",
    "    https://github.com/iit-cs579/main/blob/master/read/lru-10.pdf\n",
    "        The third and final step is to calculate for each edge e the sum\n",
    "        over all nodes Y of the fraction of shortest paths from the root\n",
    "        X to Y that go through e. This calculation involves computing this\n",
    "        sum for both nodes and edges, from the bottom. Each node other\n",
    "        than the root is given a credit of 1, representing the shortest\n",
    "        path to that node. This credit may be divided among nodes and\n",
    "        edges above, since there could be several different shortest paths\n",
    "        to the node. The rules for the calculation are as follows: ...\n",
    "\n",
    "    Params:\n",
    "      root.............The root node in the search graph (a string). We are computing\n",
    "                       shortest paths from this node to all others.\n",
    "      node2distances...dict from each node to the length of the shortest path from\n",
    "                       the root node\n",
    "      node2num_paths...dict from each node to the number of shortest paths from the\n",
    "                       root node that pass through this node.\n",
    "      node2parents.....dict from each node to the list of its parents in the search\n",
    "                       tree\n",
    "    Returns:\n",
    "      A dict mapping edges to credit value. Each key is a tuple of two strings\n",
    "      representing an edge (e.g., ('A', 'B')). Make sure each of these tuples\n",
    "      are sorted alphabetically (so, it's ('A', 'B'), not ('B', 'A')).\n",
    "\n",
    "      Any edges excluded from the results in bfs should also be exluded here.\n",
    "\n",
    "    >>> node2distances, node2num_paths, node2parents = bfs(example_graph(), 'E', 5)\n",
    "    >>> result = bottom_up('E', node2distances, node2num_paths, node2parents)\n",
    "    >>> sorted(result.items())\n",
    "    [(('A', 'B'), 1.0), (('B', 'C'), 1.0), (('B', 'D'), 3.0), (('D', 'E'), 4.5), (('D', 'G'), 0.5), (('E', 'F'), 1.5), (('F', 'G'), 0.5)]\n",
    "    \"\"\"\n",
    "    node_credit = defaultdict(float)\n",
    "    edges_credit = defaultdict(float)\n",
    "    \n",
    "    node2distances_order = sorted(node2distances.items(), key=lambda x:(-x[1], x[0]))\n",
    "    \n",
    "    for node, depth in node2distances_order:\n",
    "        node_credit[node] += 1\n",
    "        num_paths = node2num_paths[node]\n",
    "        for parents in node2parents[node]:\n",
    "            for parent in parents:\n",
    "                edge = sorted((node, parent))\n",
    "                edges_credit[tuple(sorted((node, parent)))] += node_credit[node]/num_paths\n",
    "                node_credit[parent] += node_credit[node]/num_paths\n",
    "    return edges_credit\n",
    "\n",
    "result = bottom_up('F', node2distances, node2num_paths, node2parents)\n",
    "sorted(result.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1.5, 'b': 3.5}\n",
      "Counter({'b': 3.5, 'a': 1.5})\n",
      "Counter({'b': 1.75, 'a': 0.75})\n"
     ]
    }
   ],
   "source": [
    "c = dict(a=1.5,b=3.5)\n",
    "print(c)\n",
    "a = Counter(c)\n",
    "print(a)\n",
    "for k,v in a.items():\n",
    "    a[k] /= 2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('A', 'B'), 2.0), (('A', 'C'), 1.0), (('B', 'C'), 2.0), (('B', 'D'), 6.0), (('D', 'E'), 2.5), (('D', 'F'), 2.0), (('D', 'G'), 2.5), (('E', 'F'), 1.5), (('F', 'G'), 1.5)]\n",
      "\n",
      "\n",
      "('B', 'D')\n"
     ]
    }
   ],
   "source": [
    "def approximate_betweenness(graph, max_depth):\n",
    "    \"\"\"\n",
    "    Compute the approximate betweenness of each edge, using max_depth to reduce\n",
    "    computation time in breadth-first search.\n",
    "\n",
    "    You should call the bfs and bottom_up functions defined above for each node\n",
    "    in the graph, and sum together the results. Be sure to divide by 2 at the\n",
    "    end to get the final betweenness.\n",
    "\n",
    "    Params:\n",
    "      graph.......A networkx Graph\n",
    "      max_depth...An integer representing the maximum depth to search.\n",
    "\n",
    "    Returns:\n",
    "      A dict mapping edges to betweenness. Each key is a tuple of two strings\n",
    "      representing an edge (e.g., ('A', 'B')). Make sure each of these tuples\n",
    "      are sorted alphabetically (so, it's ('A', 'B'), not ('B', 'A')).\n",
    "\n",
    "    >>> sorted(approximate_betweenness(example_graph(), 2).items())\n",
    "    [(('A', 'B'), 2.0), (('A', 'C'), 1.0), (('B', 'C'), 2.0), (('B', 'D'), 6.0), (('D', 'E'), 2.5), (('D', 'F'), 2.0), (('D', 'G'), 2.5), (('E', 'F'), 1.5), (('F', 'G'), 1.5)]\n",
    "    \"\"\"\n",
    "    edges_btw = Counter()\n",
    "    for node in graph.nodes():\n",
    "        node2distances, node2num_paths, node2parents = bfs(graph, node, max_depth)\n",
    "        edges_credit = bottom_up(node, node2distances, node2num_paths, node2parents)\n",
    "        edges_btw.update(edges_credit)\n",
    "    edges_btw = dict(edges_btw)\n",
    "    for k,v in edges_btw.items():\n",
    "        edges_btw[k] /= 2\n",
    "    return edges_btw\n",
    "        \n",
    "print(sorted(approximate_betweenness(example_graph(), 2).items()))\n",
    "print('\\n')\n",
    "print(sorted(approximate_betweenness(example_graph(), 2).items(), key=lambda x:x[1], reverse=True)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_components(graph):\n",
    "    \"\"\"\n",
    "    A helper function you may use below.\n",
    "    Returns the list of all connected components in the given graph.\n",
    "    \"\"\"\n",
    "    return [c for c in nx.connected_component_subgraphs(graph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<networkx.classes.graph.Graph object at 0x7facf5e85a58>, <networkx.classes.graph.Graph object at 0x7facf5e85898>]\n",
      "['A', 'B', 'C']\n",
      "['D', 'E', 'F', 'G']\n"
     ]
    }
   ],
   "source": [
    "def partition_girvan_newman(graph, max_depth):\n",
    "    \"\"\"\n",
    "    Use your approximate_betweenness implementation to partition a graph.\n",
    "    Unlike in class, here you will not implement this recursively. Instead,\n",
    "    just remove edges until more than one component is created, then return\n",
    "    those components.\n",
    "    That is, compute the approximate betweenness of all edges, and remove\n",
    "    them until multiple components are created.\n",
    "\n",
    "    You only need to compute the betweenness once.\n",
    "    If there are ties in edge betweenness, break by edge name (e.g.,\n",
    "    (('A', 'B'), 1.0) comes before (('B', 'C'), 1.0)).\n",
    "\n",
    "    Note: the original graph variable should not be modified. Instead,\n",
    "    make a copy of the original graph prior to removing edges.\n",
    "    See the Graph.copy method https://networkx.github.io/documentation/stable/reference/classes/generated/networkx.Graph.copy.html\n",
    "    Params:\n",
    "      graph.......A networkx Graph\n",
    "      max_depth...An integer representing the maximum depth to search.\n",
    "\n",
    "    Returns:\n",
    "      A list of networkx Graph objects, one per partition.\n",
    "\n",
    "    >>> components = partition_girvan_newman(example_graph(), 5)\n",
    "    >>> components = sorted(components, key=lambda x: sorted(x.nodes())[0])\n",
    "    >>> sorted(components[0].nodes())\n",
    "    ['A', 'B', 'C']\n",
    "    >>> sorted(components[1].nodes())\n",
    "    ['D', 'E', 'F', 'G']\n",
    "    \"\"\"\n",
    "    graph_copy = graph.copy()\n",
    "    while (len(get_components(graph_copy)) < 2):\n",
    "        edge_to_remove = sorted(approximate_betweenness(graph_copy, max_depth).items(), key=lambda x:x[1], reverse=True)[0][0]\n",
    "        graph_copy.remove_edge(*edge_to_remove)\n",
    "    return list(get_components(graph_copy))\n",
    "\n",
    "components = partition_girvan_newman(example_graph(), 4)\n",
    "components = sorted(components, key=lambda x: sorted(x.nodes())[0])\n",
    "print(components)\n",
    "print(sorted(components[0].nodes()))\n",
    "print(sorted(components[1].nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 2, 'B': 3, 'C': 2, 'D': 4, 'E': 2, 'F': 3, 'G': 2}\n",
      "dict_items([('A', 2), ('B', 3), ('C', 2), ('D', 4), ('E', 2), ('F', 3), ('G', 2)])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "degrees = dict(graph.degree())\n",
    "print(degrees)\n",
    "min_degree = 3\n",
    "nodes_subgraph = set()\n",
    "print(degrees.items())\n",
    "for node, degree in degrees.items():\n",
    "    if degree >= min_degree:\n",
    "        nodes_subgraph.update(node)\n",
    "subgraph_example = graph.subgraph(nodes_subgraph)\n",
    "nx.draw(subgraph_example, with_labels=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'D', 'F']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_subgraph(graph, min_degree):\n",
    "    \"\"\"Return a subgraph containing nodes whose degree is\n",
    "    greater than or equal to min_degree.\n",
    "    We'll use this in the main method to prune the original graph.\n",
    "\n",
    "    Params:\n",
    "      graph........a networkx graph\n",
    "      min_degree...degree threshold\n",
    "    Returns:\n",
    "      a networkx graph, filtered as defined above.\n",
    "\n",
    "    >>> subgraph = get_subgraph(example_graph(), 3)\n",
    "    >>> sorted(subgraph.nodes())\n",
    "    ['B', 'D', 'F']\n",
    "    >>> len(subgraph.edges())\n",
    "    2\n",
    "    \"\"\"\n",
    "    degrees = dict(graph.degree())\n",
    "    nodes_subgraph = set()\n",
    "    for node, degree in degrees.items():\n",
    "        if degree >= min_degree:\n",
    "            nodes_subgraph.update(node)\n",
    "    return graph.subgraph(nodes_subgraph)\n",
    "\n",
    "subgraph = get_subgraph(example_graph(), 3)\n",
    "print(sorted(subgraph.nodes()))\n",
    "#    ['B', 'D', 'F']\n",
    "len(subgraph.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(graph)\n",
    "#print(sorted(graph.degree, key=lambda x: x[1], reverse=True))\n",
    "type(get_subgraph(example_graph(), 3))\n",
    "subgraph = get_subgraph(graph, 1)\n",
    "degrees = dict(graph.degree())\n",
    "#print(degrees)\n",
    "nodes_subgraph = set()\n",
    "for node, degree in degrees.items():\n",
    "        if degree >= 35:\n",
    "            nodes_subgraph.update(node)\n",
    "#print(nodes_subgraph)\n",
    "mierda = graph.subgraph(nodes_subgraph)\n",
    "mierda.nodes()\n",
    "#print('subgraph has %d nodes and %d edges' %\n",
    " #     (len(subgraph.nodes()), subgraph.number_of_edges()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def volume(nodes, graph):\n",
    "    \"\"\"\n",
    "    Compute the volume for a list of nodes, which\n",
    "    is the number of edges in `graph` with at least one end in\n",
    "    nodes.\n",
    "    Params:\n",
    "      nodes...a list of strings for the nodes to compute the volume of.\n",
    "      graph...a networkx graph\n",
    "\n",
    "    >>> volume(['A', 'B', 'C'], example_graph())\n",
    "    4\n",
    "    \"\"\"\n",
    "    ext_edges = 0\n",
    "    int_edges = 0\n",
    "    for node in nodes:\n",
    "        for neighbor in graph.neighbors(node):\n",
    "            if neighbor not in nodes:\n",
    "                ext_edges += 1\n",
    "            else:\n",
    "                int_edges +=1\n",
    "    return round(int_edges/2 + ext_edges)\n",
    "volume(['D', 'E', 'F', 'G'], example_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cut(S, T, graph):\n",
    "    \"\"\"\n",
    "    Compute the cut-set of the cut (S,T), which is\n",
    "    the set of edges that have one endpoint in S and\n",
    "    the other in T.\n",
    "    Params:\n",
    "      S.......set of nodes in first subset\n",
    "      T.......set of nodes in second subset\n",
    "      graph...networkx graph\n",
    "    Returns:\n",
    "      An int representing the cut-set.\n",
    "\n",
    "    >>> cut(['A', 'B', 'C'], ['D', 'E', 'F', 'G'], example_graph())\n",
    "    1\n",
    "    \"\"\"\n",
    "    cut_set = 0\n",
    "    for node in S:\n",
    "        for neighbor in graph.neighbors(node):\n",
    "            if neighbor in T:\n",
    "                cut_set += 1\n",
    "    return cut_set\n",
    "                \n",
    "cut(['A', 'B', 'C', 'D', 'E', 'G'], ['F'], example_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3333333333333333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm_cut(S, T, graph):\n",
    "    \"\"\"\n",
    "    The normalized cut value for the cut S/T. (See lec06.)\n",
    "    Params:\n",
    "      S.......set of nodes in first subset\n",
    "      T.......set of nodes in second subset\n",
    "      graph...networkx graph\n",
    "    Returns:\n",
    "      An float representing the normalized cut value\n",
    "\n",
    "    \"\"\"\n",
    "    return (cut(S, T, graph)*(1/volume(S, graph) + 1/volume(T, graph)))\n",
    "norm_cut(['A', 'B', 'C', 'D', 'E', 'G'], ['F'], graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = nx.boundary_expansion(graph, ['D'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module networkx.algorithms.cuts in networkx.algorithms:\n",
      "\n",
      "NAME\n",
      "    networkx.algorithms.cuts - Functions for finding and evaluating cuts in a graph.\n",
      "\n",
      "FUNCTIONS\n",
      "    boundary_expansion(G, S)\n",
      "        Returns the boundary expansion of the set `S`.\n",
      "        \n",
      "        The *boundary expansion* is the quotient of the size of the edge\n",
      "        boundary and the cardinality of *S*. [1]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        G : NetworkX graph\n",
      "        \n",
      "        S : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        number\n",
      "            The boundary expansion of the set `S`.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        edge_expansion\n",
      "        mixing_expansion\n",
      "        node_expansion\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Vadhan, Salil P.\n",
      "               \"Pseudorandomness.\"\n",
      "               *Foundations and Trends in Theoretical Computer Science*\n",
      "               7.1–3 (2011): 1–336.\n",
      "               <https://doi.org/10.1561/0400000010>\n",
      "    \n",
      "    conductance(G, S, T=None, weight=None)\n",
      "        Returns the conductance of two sets of nodes.\n",
      "        \n",
      "        The *conductance* is the quotient of the cut size and the smaller of\n",
      "        the volumes of the two sets. [1]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        G : NetworkX graph\n",
      "        \n",
      "        S : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        T : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        weight : object\n",
      "            Edge attribute key to use as weight. If not specified, edges\n",
      "            have weight one.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        number\n",
      "            The conductance between the two sets `S` and `T`.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        cut_size\n",
      "        edge_expansion\n",
      "        normalized_cut_size\n",
      "        volume\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] David Gleich.\n",
      "               *Hierarchical Directed Spectral Graph Partitioning*.\n",
      "               <https://www.cs.purdue.edu/homes/dgleich/publications/Gleich%202005%20-%20hierarchical%20directed%20spectral.pdf>\n",
      "    \n",
      "    cut_size(G, S, T=None, weight=None)\n",
      "        Returns the size of the cut between two sets of nodes.\n",
      "        \n",
      "        A *cut* is a partition of the nodes of a graph into two sets. The\n",
      "        *cut size* is the sum of the weights of the edges \"between\" the two\n",
      "        sets of nodes.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        G : NetworkX graph\n",
      "        \n",
      "        S : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        T : sequence\n",
      "            A sequence of nodes in `G`. If not specified, this is taken to\n",
      "            be the set complement of `S`.\n",
      "        \n",
      "        weight : object\n",
      "            Edge attribute key to use as weight. If not specified, edges\n",
      "            have weight one.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        number\n",
      "            Total weight of all edges from nodes in set `S` to nodes in\n",
      "            set `T` (and, in the case of directed graphs, all edges from\n",
      "            nodes in `T` to nodes in `S`).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        In the graph with two cliques joined by a single edges, the natural\n",
      "        bipartition of the graph into two blocks, one for each clique,\n",
      "        yields a cut of weight one::\n",
      "        \n",
      "            >>> G = nx.barbell_graph(3, 0)\n",
      "            >>> S = {0, 1, 2}\n",
      "            >>> T = {3, 4, 5}\n",
      "            >>> nx.cut_size(G, S, T)\n",
      "            1\n",
      "        \n",
      "        Each parallel edge in a multigraph is counted when determining the\n",
      "        cut size::\n",
      "        \n",
      "            >>> G = nx.MultiGraph(['ab', 'ab'])\n",
      "            >>> S = {'a'}\n",
      "            >>> T = {'b'}\n",
      "            >>> nx.cut_size(G, S, T)\n",
      "            2\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In a multigraph, the cut size is the total weight of edges including\n",
      "        multiplicity.\n",
      "    \n",
      "    edge_expansion(G, S, T=None, weight=None)\n",
      "        Returns the edge expansion between two node sets.\n",
      "        \n",
      "        The *edge expansion* is the quotient of the cut size and the smaller\n",
      "        of the cardinalities of the two sets. [1]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        G : NetworkX graph\n",
      "        \n",
      "        S : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        T : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        weight : object\n",
      "            Edge attribute key to use as weight. If not specified, edges\n",
      "            have weight one.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        number\n",
      "            The edge expansion between the two sets `S` and `T`.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        boundary_expansion\n",
      "        mixing_expansion\n",
      "        node_expansion\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Fan Chung.\n",
      "               *Spectral Graph Theory*.\n",
      "               (CBMS Regional Conference Series in Mathematics, No. 92),\n",
      "               American Mathematical Society, 1997, ISBN 0-8218-0315-8\n",
      "               <http://www.math.ucsd.edu/~fan/research/revised.html>\n",
      "    \n",
      "    mixing_expansion(G, S, T=None, weight=None)\n",
      "        Returns the mixing expansion between two node sets.\n",
      "        \n",
      "        The *mixing expansion* is the quotient of the cut size and twice the\n",
      "        number of edges in the graph. [1]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        G : NetworkX graph\n",
      "        \n",
      "        S : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        T : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        weight : object\n",
      "            Edge attribute key to use as weight. If not specified, edges\n",
      "            have weight one.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        number\n",
      "            The mixing expansion between the two sets `S` and `T`.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        boundary_expansion\n",
      "        edge_expansion\n",
      "        node_expansion\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Vadhan, Salil P.\n",
      "               \"Pseudorandomness.\"\n",
      "               *Foundations and Trends\n",
      "               in Theoretical Computer Science* 7.1–3 (2011): 1–336.\n",
      "               <https://doi.org/10.1561/0400000010>\n",
      "    \n",
      "    node_expansion(G, S)\n",
      "        Returns the node expansion of the set `S`.\n",
      "        \n",
      "        The *node expansion* is the quotient of the size of the node\n",
      "        boundary of *S* and the cardinality of *S*. [1]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        G : NetworkX graph\n",
      "        \n",
      "        S : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        number\n",
      "            The node expansion of the set `S`.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        boundary_expansion\n",
      "        edge_expansion\n",
      "        mixing_expansion\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Vadhan, Salil P.\n",
      "               \"Pseudorandomness.\"\n",
      "               *Foundations and Trends\n",
      "               in Theoretical Computer Science* 7.1–3 (2011): 1–336.\n",
      "               <https://doi.org/10.1561/0400000010>\n",
      "    \n",
      "    normalized_cut_size(G, S, T=None, weight=None)\n",
      "        Returns the normalized size of the cut between two sets of nodes.\n",
      "        \n",
      "        The *normalized cut size* is the cut size times the sum of the\n",
      "        reciprocal sizes of the volumes of the two sets. [1]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        G : NetworkX graph\n",
      "        \n",
      "        S : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        T : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        weight : object\n",
      "            Edge attribute key to use as weight. If not specified, edges\n",
      "            have weight one.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        number\n",
      "            The normalized cut size between the two sets `S` and `T`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In a multigraph, the cut size is the total weight of edges including\n",
      "        multiplicity.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        conductance\n",
      "        cut_size\n",
      "        edge_expansion\n",
      "        volume\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] David Gleich.\n",
      "               *Hierarchical Directed Spectral Graph Partitioning*.\n",
      "               <https://www.cs.purdue.edu/homes/dgleich/publications/Gleich%202005%20-%20hierarchical%20directed%20spectral.pdf>\n",
      "    \n",
      "    volume(G, S, weight=None)\n",
      "        Returns the volume of a set of nodes.\n",
      "        \n",
      "        The *volume* of a set *S* is the sum of the (out-)degrees of nodes\n",
      "        in *S* (taking into account parallel edges in multigraphs). [1]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        G : NetworkX graph\n",
      "        \n",
      "        S : sequence\n",
      "            A sequence of nodes in `G`.\n",
      "        \n",
      "        weight : object\n",
      "            Edge attribute key to use as weight. If not specified, edges\n",
      "            have weight one.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        number\n",
      "            The volume of the set of nodes represented by `S` in the graph\n",
      "            `G`.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        conductance\n",
      "        cut_size\n",
      "        edge_expansion\n",
      "        edge_boundary\n",
      "        normalized_cut_size\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] David Gleich.\n",
      "               *Hierarchical Directed Spectral Graph Partitioning*.\n",
      "               <https://www.cs.purdue.edu/homes/dgleich/publications/Gleich%202005%20-%20hierarchical%20directed%20spectral.pdf>\n",
      "\n",
      "DATA\n",
      "    __all__ = ['boundary_expansion', 'conductance', 'cut_size', 'edge_expa...\n",
      "\n",
      "FILE\n",
      "    /home/agericke/anaconda3/lib/python3.7/site-packages/networkx/algorithms/cuts.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nx.cuts)\n",
    "#b = list(nx.(graph, 3))\n",
    "#print(b)#print(graph.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nx)\n",
    "depths = list(range(1,5))\n",
    "type(depths)\n",
    "depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force_norm_cut(graph, max_size):\n",
    "    \"\"\"\n",
    "    Enumerate over all possible cuts of the graph, up to max_size, and compute the norm cut score.\n",
    "    Params:\n",
    "        graph......graph to be partitioned\n",
    "        max_size...maximum number of edges to consider for each cut.\n",
    "                   E.g, if max_size=2, consider removing edge sets\n",
    "                   of size 1 or 2 edges.\n",
    "    Returns:\n",
    "        (unsorted) list of (score, edge_list) tuples, where\n",
    "        score is the norm_cut score for each cut, and edge_list\n",
    "        is the list of edges (source, target) for each cut.\n",
    "        \n",
    "\n",
    "    Note: only return entries if removing the edges results in exactly\n",
    "    two connected components.\n",
    "\n",
    "    You may find itertools.combinations useful here.\n",
    "\n",
    "    >>> r = brute_force_norm_cut(example_graph(), 1)\n",
    "    >>> len(r)\n",
    "    1\n",
    "    >>> r\n",
    "    [(0.41666666666666663, [('B', 'D')])]\n",
    "    >>> r = brute_force_norm_cut(example_graph(), 2)\n",
    "    >>> len(r)\n",
    "    14\n",
    "    >>> sorted(r)[0]\n",
    "    (0.41666666666666663, [('A', 'B'), ('B', 'D')])\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1.2222222222222223), (2, 0.41666666666666663), (3, 0.41666666666666663), (4, 0.41666666666666663)]\n"
     ]
    }
   ],
   "source": [
    "def score_max_depths(graph, max_depths):\n",
    "    \"\"\"\n",
    "    In order to assess the quality of the approximate partitioning method\n",
    "    we've developed, we will run it with different values for max_depth\n",
    "    and see how it affects the norm_cut score of the resulting partitions.\n",
    "    Recall that smaller norm_cut scores correspond to better partitions.\n",
    "\n",
    "    Params:\n",
    "      graph........a networkx Graph\n",
    "      max_depths...a list of ints for the max_depth values to be passed\n",
    "                   to calls to partition_girvan_newman\n",
    "\n",
    "    Returns:\n",
    "      A list of (int, float) tuples representing the max_depth and the\n",
    "      norm_cut value obtained by the partitions returned by\n",
    "      partition_girvan_newman. See Log.txt for an example.\n",
    "    \"\"\"\n",
    "    result = defaultdict(float)\n",
    "    for i in max_depths:\n",
    "        components = partition_girvan_newman(graph, i)\n",
    "        norm_cut_val = norm_cut(sorted(components[0].nodes()), sorted(components[1].nodes()), graph)\n",
    "        result[i] = norm_cut_val\n",
    "    return sorted(result.items())\n",
    "\n",
    "depths = list(range(1,5))\n",
    "result = score_max_depths(example_graph(), depths)\n",
    "print(result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f9781cced111>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#dir(graph)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#help(graph.neighbors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "graph = example_graph()\n",
    "#type(graph)\n",
    "#dir(graph)\n",
    "#help(graph.neighbors)\n",
    "sorted(graph.neighbors('A'))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'D']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "## Link prediction\n",
    "\n",
    "# Next, we'll consider the link prediction problem. In particular,\n",
    "# we will remove 5 of the accounts that Bill Gates likes and\n",
    "# compute our accuracy at recovering those links.\n",
    "\n",
    "def make_training_graph(graph, test_node, n):\n",
    "    \"\"\"\n",
    "    To make a training graph, we need to remove n edges from the graph.\n",
    "    As in lecture, we'll assume there is a test_node for which we will\n",
    "    remove some edges. Remove the edges to the first n neighbors of\n",
    "    test_node, where the neighbors are sorted alphabetically.\n",
    "    E.g., if 'A' has neighbors 'B' and 'C', and n=1, then the edge\n",
    "    ('A', 'B') will be removed.\n",
    "\n",
    "    Be sure to *copy* the input graph prior to removing edges.\n",
    "\n",
    "    Params:\n",
    "      graph.......a networkx Graph\n",
    "      test_node...a string representing one node in the graph whose\n",
    "                  edges will be removed.\n",
    "      n...........the number of edges to remove.\n",
    "\n",
    "    Returns:\n",
    "      A *new* networkx Graph with n edges removed.\n",
    "\n",
    "    In this doctest, we remove edges for two friends of D:\n",
    "    >>> g = example_graph()\n",
    "    >>> sorted(g.neighbors('D'))\n",
    "    ['B', 'E', 'F', 'G']\n",
    "    >>> train_graph = make_training_graph(g, 'D', 2)\n",
    "    >>> sorted(train_graph.neighbors('D'))\n",
    "    ['F', 'G']\n",
    "    \"\"\"\n",
    "    graph_copy = graph.copy()\n",
    "    neighbors = sorted(graph_copy.neighbors(test_node))\n",
    "    remove_edges = 0\n",
    "    while (remove_edges < n and remove_edges < len(neighbors)):\n",
    "        graph_copy.remove_edge(test_node, neighbors[remove_edges])\n",
    "        remove_edges += 1\n",
    "    return graph_copy\n",
    "\n",
    "g = example_graph()\n",
    "print(sorted(g.neighbors('B')))\n",
    "#['B', 'E', 'F', 'G']\n",
    "train_graph = make_training_graph(g, 'B', 4)\n",
    "print(sorted(train_graph.neighbors('B')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('D', 'E'), 0.5), (('D', 'A'), 0.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard(graph, node, k):\n",
    "    \"\"\"\n",
    "    Compute the k highest scoring edges to add to this node based on\n",
    "    the Jaccard similarity measure.\n",
    "    Note that we don't return scores for edges that already appear in the graph.\n",
    "\n",
    "    Params:\n",
    "      graph....a networkx graph\n",
    "      node.....a node in the graph (a string) to recommend links for.\n",
    "      k........the number of links to recommend.\n",
    "\n",
    "    Returns:\n",
    "      A list of tuples in descending order of score representing the\n",
    "      recommended new edges. Ties are broken by\n",
    "      alphabetical order of the terminal node in the edge.\n",
    "\n",
    "    In this example below, we remove edges (D, B) and (D, E) from the\n",
    "    example graph. The top two edges to add according to Jaccard are\n",
    "    (D, E), with score 0.5, and (D, A), with score 0. (Note that all the\n",
    "    other remaining edges have score 0, but 'A' is first alphabetically.)\n",
    "\n",
    "    >>> g = example_graph()\n",
    "    >>> train_graph = make_training_graph(g, 'D', 2)\n",
    "    >>> jaccard(train_graph, 'D', 2)\n",
    "    [(('D', 'E'), 0.5), (('D', 'A'), 0.0)]\n",
    "    \"\"\"\n",
    "    new_edges = defaultdict(float)\n",
    "    neighbors = set(graph.neighbors(node))\n",
    "    scores = []\n",
    "    for n in graph.nodes():\n",
    "        if (graph.has_edge(node, n) or node==n):\n",
    "            continue\n",
    "        neighbors2 = set(graph.neighbors(n))\n",
    "        new_edges[tuple((node, n))] = len(neighbors & neighbors2) / len(neighbors | neighbors2)\n",
    "        #print(new_edges)\n",
    "    return sorted(new_edges.items(), key=lambda x: (-x[1], x[0][1]))[:k]\n",
    "\n",
    "g = example_graph()\n",
    "train_graph = make_training_graph(g, 'D', 2)\n",
    "jaccard(train_graph, 'D', 2)\n",
    "#    [(('D', 'E'), 0.5), (('D', 'A'), 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method has_edge in module networkx.classes.graph:\n",
      "\n",
      "has_edge(u, v) method of networkx.classes.graph.Graph instance\n",
      "    Return True if the edge (u, v) is in the graph.\n",
      "    \n",
      "    This is the same as `v in G[u]` without KeyError exceptions.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    u, v : nodes\n",
      "        Nodes can be, for example, strings or numbers.\n",
      "        Nodes must be hashable (and not None) Python objects.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    edge_ind : bool\n",
      "        True if edge is in the graph, False otherwise.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> G = nx.path_graph(4)  # or DiGraph, MultiGraph, MultiDiGraph, etc\n",
      "    >>> G.has_edge(0, 1)  # using two nodes\n",
      "    True\n",
      "    >>> e = (0, 1)\n",
      "    >>> G.has_edge(*e)  #  e is a 2-tuple (u, v)\n",
      "    True\n",
      "    >>> e = (0, 1, {'weight':7})\n",
      "    >>> G.has_edge(*e[:2])  # e is a 3-tuple (u, v, data_dictionary)\n",
      "    True\n",
      "    \n",
      "    The following syntax are equivalent:\n",
      "    \n",
      "    >>> G.has_edge(0, 1)\n",
      "    True\n",
      "    >>> 1 in G[0]  # though this gives KeyError if 0 not in G\n",
      "    True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(graph.has_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "Error. You must provide a non-empty list of edges\n"
     ]
    }
   ],
   "source": [
    "def evaluate(predicted_edges, graph):\n",
    "    \"\"\"\n",
    "    Return the fraction of the predicted edges that exist in the graph.\n",
    "\n",
    "    Args:\n",
    "      predicted_edges...a list of edges (tuples) that are predicted to\n",
    "                        exist in this graph\n",
    "      graph.............a networkx Graph\n",
    "\n",
    "    Returns:\n",
    "      The fraction of edges in predicted_edges that exist in the graph.\n",
    "\n",
    "    In this doctest, the edge ('D', 'E') appears in the example_graph,\n",
    "    but ('D', 'A') does not, so 1/2 = 0.5\n",
    "\n",
    "    >>> evaluate([('D', 'E'), ('D', 'A')], example_graph())\n",
    "    0.5\n",
    "    \"\"\"\n",
    "    exist = 0\n",
    "    if (len(predicted_edges) == 0):\n",
    "        return print(\"Error. You must provide a non-empty list of edges\")\n",
    "    for edge in predicted_edges:\n",
    "        if (graph.has_edge(*edge)):\n",
    "            exist += 1\n",
    "    return (exist/len(predicted_edges))\n",
    "\n",
    "print(evaluate([('D', 'E'), ('D', 'A'), ('D', 'B'), ('B', 'B'), ('Z', 'B')], example_graph()))\n",
    "evaluate([], example_graph())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
